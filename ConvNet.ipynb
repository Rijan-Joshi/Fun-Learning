{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMxkwEG2X/yT6LnVUZo0Yhm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rijan-Joshi/Fun-Learning/blob/main/ConvNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ConvNet From Scratch with augmentations**"
      ],
      "metadata": {
        "id": "U6jstdpA0dbV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This will contain:\n",
        "1. image augmentation for increasing the volume of input  \n",
        "2. visualization of intermediate features and images\n",
        "3. Fine-tuning the known architecture for the sake of learning\n",
        "\n",
        "All will be coded in PyTorch\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "m4LGipAK0poK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "AlUhi_tOwvyK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the datasets\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(\n",
        "    root = 'data',\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform = transform\n",
        ")\n",
        "\n",
        "test_dataset = datasets.CIFAR10(\n",
        "    root = 'data',\n",
        "    train = False,\n",
        "    download = True,\n",
        "    transform = transform\n",
        ")"
      ],
      "metadata": {
        "id": "tTHNcNqD2eVU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4c0002a-293a-412a-fb93-364120f0c3f0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:06<00:00, 28.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Since we are using the concept of data augmentation, we will be using less samples of data. Currently, we have 5000 samples for cat and dogs each. But, we will use the dataset with 1000 training images, 500 validation imgages and 1000 test images\""
      ],
      "metadata": {
        "id": "iG8gTt0B-kot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Subset\n",
        "def create_balanced_subset(dataset, class_indices, start_index, end_index):\n",
        "\n",
        "  targets = np.array(dataset.targets)\n",
        "  selected_indices = []\n",
        "\n",
        "  for cls in class_indices:\n",
        "    indices = np.where(targets == cls)[0]\n",
        "    selected_indices.extend(indices[start_index: end_index])\n",
        "\n",
        "  dataset = Subset(dataset, selected_indices)\n",
        "  return dataset\n",
        "\n",
        "train_data = create_balanced_subset(train_dataset, [3,5], 0, 1000)\n",
        "validation_data = create_balanced_subset(train_dataset, [3,5], 1000, 1500)\n",
        "test_data = create_balanced_subset(test_dataset, [3,5], 0, 1000)"
      ],
      "metadata": {
        "id": "UcY7v53c7fEj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_subset_balance(subset, name=\"Subset\"):\n",
        "    # This pulls labels from the original dataset using the subset's internal indices\n",
        "    labels = [subset.dataset.targets[i] for i in subset.indices]\n",
        "\n",
        "    unique, counts = np.unique(labels, return_counts=True)\n",
        "    print(f\"--- {name} ---\")\n",
        "    print(f\"Total samples: {len(subset)}\")\n",
        "    for cls, count in zip(unique, counts):\n",
        "        print(f\"Class {cls}: {count} samples\")\n",
        "\n",
        "check_subset_balance(train_data, \"Training Set\")\n",
        "check_subset_balance(validation_data, \"Validation Set\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjdTmfaW9jo1",
        "outputId": "6982bafa-7786-4b49-8822-2334149aa32f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Training Set ---\n",
            "Total samples: 2000\n",
            "Class 3: 1000 samples\n",
            "Class 5: 1000 samples\n",
            "--- Validation Set ---\n",
            "Total samples: 1000\n",
            "Class 3: 500 samples\n",
            "Class 5: 500 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Changing the class 3 -> 0 and 5 -> 1\n",
        "class DatasetWrapper:\n",
        "  def __init__(self, subset, mapping = {3 : 0, 5: 1}):\n",
        "    self.subset = subset\n",
        "    self.mapping = mapping\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    image, target = self.subset[index]\n",
        "    return image, self.mapping[target]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.subset)\n",
        "\n",
        "train_ready = DatasetWrapper(train_data)\n",
        "validation_ready = DatasetWrapper(validation_data)\n",
        "test_ready = DatasetWrapper(test_data)"
      ],
      "metadata": {
        "id": "wY_11HZ-QhxO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating dataloader\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_ready, batch_size, shuffle = True)\n",
        "val_loader = DataLoader(validation_ready, batch_size, shuffle = True)\n",
        "test_loader = DataLoader(test_ready, batch_size, shuffle = True)"
      ],
      "metadata": {
        "id": "eUxtFD-fU_HM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = next(iter(train_loader))\n",
        "\n",
        "images = images[:32].numpy()\n",
        "images = np.transpose(images, (0, 2, 3, 1)) #Channel to the last\n",
        "label_mappings  = {\n",
        "    0: \"Cat\",\n",
        "    1: \"Dog\"\n",
        "}\n",
        "plt.figure(figsize = (20, 10))\n",
        "for i in range(len(images)):\n",
        "  plt.subplot(4, 8, i + 1)\n",
        "  plt.imshow(images[i])\n",
        "  plt.xlabel(f\"Label: {label_mappings[labels[i].item()]}\")\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "plt.show()\n",
        "#Visualizing the first batch of the images"
      ],
      "metadata": {
        "id": "gJLD_kZLWetb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images.size()"
      ],
      "metadata": {
        "id": "KO8k5Mhxm4tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n"
      ],
      "metadata": {
        "id": "jqJBIEeQBDFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules import activation\n",
        "from torchsummary import summary\n",
        "#Defining the model\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.ConV_stack = nn.Sequential(\n",
        "\n",
        "        nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 2),\n",
        "\n",
        "        nn.Conv2d(in_channels=32, out_channels=64, kernel_size = 3, padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 2),\n",
        "\n",
        "        nn.Conv2d(in_channels = 64, out_channels=128, kernel_size = 3, padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 2),\n",
        "\n",
        "        nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = 3, padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 2),\n",
        "\n",
        "        nn.Conv2d(in_channels = 256, out_channels = 512, kernel_size = 3, padding = 1),\n",
        "        nn.ReLU(),\n",
        "\n",
        "        nn.AdaptiveAvgPool2d(1),\n",
        "        nn.Flatten(),\n",
        "\n",
        "        nn.Linear(512, 1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self, X):\n",
        "    Y = self.ConV_stack(X)\n",
        "    return Y"
      ],
      "metadata": {
        "id": "6qD5jXS5B1Rl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.accelerator.current_accelerator() if torch.accelerator.is_available() else \"cpu\"\n",
        "model = NeuralNetwork().to(device)\n",
        "summary(model, (3, 32, 32))"
      ],
      "metadata": {
        "id": "AC9PpyvSMs6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining the optimizer and the loss function for the model\n",
        "optimizer = torch.optim.RMSprop(model.parameters(), lr = 1e-3)\n",
        "criterion = nn.BCELoss()"
      ],
      "metadata": {
        "id": "SHGtaWs_RQHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining the training function\n",
        "\n",
        "def train(dataloader, model, optimizer, loss_fn):\n",
        "  num_batches = len(dataloader)\n",
        "\n",
        "  model.train()\n",
        "  running_loss = 0.0\n",
        "  correct = 0\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device).float().unsqueeze(1)\n",
        "\n",
        "    y_pred = model.forward(X)\n",
        "    loss = loss_fn(y_pred, y)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    pred = (y_pred > 0.5).float()\n",
        "    correct += (pred == y).sum().item()\n",
        "\n"
      ],
      "metadata": {
        "id": "wM2iWAc4TIpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining the test function\n",
        "def test(dataloader, model, loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "  batches = len(dataloader)\n",
        "\n",
        "  test_loss = 0\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "      X, y = X.to(device), y.to(device).float().unsqueeze(1)\n",
        "\n",
        "      y_pred = model.forward(X)\n",
        "      loss = loss_fn(y, y_pred)\n",
        "\n",
        "      test_loss += loss.item()\n",
        "\n",
        "  avg_test_loss = test_loss / batches\n"
      ],
      "metadata": {
        "id": "4Y3VwkP6VUZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T4ouPYw4Yila"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}